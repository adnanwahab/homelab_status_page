<!doctype html>
<meta charset="utf-8" />
<title>Breakout!</title>
<link rel="stylesheet" type="text/css" href="./inspector.css" />
<body>
    <script type="module">
        import define from "./index.js";
        //import {Inspector} from "https://unpkg.com/@observablehq/inspector@5.0.1/src/index.js?module"
        //import {Runtime} from "https://unpkg.com/@observablehq/inspector@5.0.1/src/index.js?module"
        //import {Runtime } from "https://cdn.jsdelivr.net/npm/@observablehq/runtime@5/dist/runtime.js";

        //import {Inspector} from "./runtime.js";
        //import {Runtime, Library} from "./runtime.js";
        //import {Library} from "./runtime.js";
        //import {Runtime, Library, Inspector} from "./runtime.js";
        //import {Runtime, Library, Inspector} from "./observable-runtime/dist/runtime.js";
        //import {Runtime as Runtime_2} from "./observable-runtime/src/index.js";
        import { Runtime, Inspector, Library } from "./runtime/src/index.js";
        // https://observablehq.com/@fil/worker-utility-update


        //not deprecated -
        // Generators.input
        //Generators.observe - servers are long running
        //Generators.queue
        //-----

        //const stdlib = new (_stdlib.Library())()

        // const worker = stdlib.Generators.worker(`
        // onmessage = function({data}) {
        //   postMessage({echo: data});
        // };
        // `)

        import * as _stdlib from "./runtime/src/stdlib/src/index.js";
        const stdlib = new _stdlib.Library();

        // const source = `
        // function () {
        // return console.log('is this on server or client?);
        // }
        // `;

      

        //exec w/o worker - dont user ersverice workers yet - but also - think of fan out - 1000 servers - make or find 
//whats ss only?? find out - > show 

       
// const deno_3 = `
// console.log("hello_world");
// `
//console.log('deno_2')

// const worker = stdlib.Generators.worker(`
//         const serverUrl = self.location.origin + '/observable-server?type=deno';
//             console.log(serverUrl)
//             fetch(serverUrl, {  
//                 method: "POST",
//                 headers: { "Content-Type": "application/json"},
//                 body: JSON.stringify({code: \`${deno_3}\`})
//             })
//             .then(response => response.json())
//             .then(data => {
//                 console.log('Response from server:', data);
//                 postMessage(data);
//                 return data
//             })
//             .catch(error => {
//                 console.error('Error:', error);
//                 postMessage({ error: error.message });
//             });
//         `, 'deno')
const deno_2 = `
const bytes = new Uint8Array([72, 101, 108, 108, 111]);
await Deno.writeFile("hello.txt", bytes, { mode: 0o644 });
await Deno.writeTextFile("hello.txt", "Hello World");
Deno.writeFileSync("hello.txt", bytes);
Deno.writeTextFileSync("hello.txt", "Hello World");
const file = await Deno.create("hello.txt");
const written = await file.write(bytes);
console.log("written " + written + " bytes.");
const writer = file.writable.getWriter();
await writer.write(new TextEncoder().encode("World!"));
await writer.close();
`

//const deno_cell = async function () {

    
     const deno_cell = function () {






        const deno_3 = `
      import { copyToBuffer, createPng, Dimensions } from "../utils.ts";
import { createCapture } from "std/webgpu";
import { serveDir, serveFile } from "jsr:@std/http/file-server";

const dimensions: Dimensions = {
  width: 200,
  height: 200,
};

const adapter = await navigator.gpu.requestAdapter();
const device = await adapter?.requestDevice();

if (!device) {
  console.error("no suitable adapter found");
  Deno.exit(0);
}

const shaderCode = \`
@vertex
fn vs_main(@builtin(vertex_index) in_vertex_index: u32) -> @builtin(position) vec4<f32> {
    let x = f32(i32(in_vertex_index) - 1);
    let y = f32(i32(in_vertex_index & 1u) * 2 - 1);
    return vec4<f32>(x, y, 0.0, 1.0);
}

@fragment
fn fs_main() -> @location(0) vec4<f32> {
    return vec4<f32>(1.0, 0.0, 0.0, 1.0);
}
\`;

const shaderModule = device.createShaderModule({
  code: shaderCode,
});

const pipelineLayout = device.createPipelineLayout({
  bindGroupLayouts: [],
});

const renderPipeline = device.createRenderPipeline({
  layout: pipelineLayout,
  vertex: {
    module: shaderModule,
    entryPoint: "vs_main",
  },
  fragment: {
    module: shaderModule,
    entryPoint: "fs_main",
    targets: [
      {
        format: "rgba8unorm-srgb",
      },
    ],
  },
});

const { texture, outputBuffer } = createCapture(
  device,
  dimensions.width,
  dimensions.height,
);

const encoder = device.createCommandEncoder();
const renderPass = encoder.beginRenderPass({
  colorAttachments: [
    {
      view: texture.createView(),
      storeOp: "store",
      loadOp: "clear",
      clearValue: [0, 1, 0, 1],
    },
  ],
});
renderPass.setPipeline(renderPipeline);
renderPass.draw(3, 1);
renderPass.end();

copyToBuffer(encoder, texture, outputBuffer, dimensions);

device.queue.submit([encoder.finish()]);

await createPng(outputBuffer, dimensions);


async function readImageAndConvertToBase64(filepath) {
    try {
        // Deno 2 simplifies file reading with Deno.readFile
        const fileData = await Deno.readFile(filepath);

        // Convert the Uint8Array to a Base64 string
        const base64String = btoa(new TextDecoder('latin1').decode(fileData));

        return base64String;
    } catch (error) {
        console.error('Error reading the file:', error);
        return null;
    }
}



// Usage
//const filepath = "./output.png";
const file_path = '/Users/shelbernstein/hashirama/services/deno-webgpu/hello-triangle/'


Deno.serve(
  { port: 3000, hostname: "127.0.0.1" },

(req: Request) => {
  const pathname = new URL(req.url).pathname;

  if (pathname === "/output.png") {
    return serveFile(req, 'output.png');
  }

  if (pathname.startsWith("/file_path")) {
    return serveDir(req, {
      fsRoot: file_path,
      urlRoot: "file_path",
    });
  }

  return new Response("404: Not Found", {
    status: 404,
  });
});




`



let shit = `<img src="http://localhost:3000/output.png">`
setTimeout(() => {
    document.body.innerHTML += shit
}, 1000)

//jp 
//fnish it by 10am 
// this proj gets you to l2- halfway to senior /?? - devops  - over 2 monhs 
//he hates tangle
// smalltalk + flex +all alan k y (how would brret victor do this ? he probalbly has "no server coe + some app code")
// how do you handle - if user - calls deno.fork - or deno.make new process - how to handle that stdout? 
return deno_3
    }


const deno_3 = deno_cell();


function deno_cell_fetch(code) {
const serverUrl = 'http://localhost:8000/observable-server'
const a = fetch(serverUrl, {  
                method: "POST",
                headers: { "Content-Type": "application/json"},
                body: JSON.stringify({
                runtime: 'deno',
                filename: 'deno_test.ts',
                code: code
                })
            })
            .then(response => response.json())
            .then(data => {
                //console.log('Response from server:', data.fileOutput.split('\n')
                console.log('Response from server:', data.fileOutput

                );
                //postMessage(data);
                return data
            })
            .catch(error => {
                console.error('Error:', error);
                //postMessage({ error: error.message });
            });
        }

//deno_cell()
// =20% obs audience = maybe double over 5 years 
//make python - notebook async first - proboaly exitst but w/e 
/// llm sheild - llmama fast or whateer 
            function bun_cell() {
                //write a llm fn - a test fn for it to check if valid in that env - etc
  const isBun = `
        import { readdirSync } from 'fs'; 
        const files = readdirSync('./');
        console.log(files); 
         `

         console.log(' about to run bun ')

        const worker = stdlib.Generators.worker(`
        const serverUrl = self.location.origin + '/observable-server';

            fetch(serverUrl, {  
                method: "POST",
                headers: { "Content-Type": "application/json"},
                body: JSON.stringify({
                runtime: 'bun',
                filename: 'bun_test.js',
                code: \`${isBun}\`
                })
            })
            .then(response => response.json())
            .then(data => {
                console.log('Response from server:', data);
                postMessage(data);
                return data
            })
            .catch(error => {
                console.error('Error:', error);
                postMessage({ error: error.message });
            });
        `, 'bun')
            }
//deno_cell_fetch(deno_3)


// if client side only - auto-eval dependent cells = always probabyl ok 
// if server side only - auto-eval dependent cells  - make ok === via llm ? or like at least "are you rsure??? lol"
// suggestion - 1,2,3 - ? 
//https://github.com/googlecolab/colabtools
            //bun_cell()
        // const worker = stdlib.Generators.worker(`
        // const serverUrl = self.location.origin + '/observable-server';

        //     fetch(serverUrl, {  
        //         method: "POST",
        //         headers: { "Content-Type": "application/json"},
        //         body: JSON.stringify({code: \`${isBun}\`})
        //     })
        //     .then(response => response.json())
        //     .then(data => {
        //         console.log('Response from server:', data);
        //         postMessage(data);
        //         return data
        //     })
        //     .catch(error => {
        //         console.error('Error:', error);
        //         postMessage({ error: error.message });
        //     });
        // `, 'deno')


        //window.worker = worker
        //Object.keys(worker) // "next", "return" "throw"

        //stdlib.Generators.observe((next) => {});

        //worker.postMessage(10);

        //https://observablehq.com/@observablehq?tab=profile&type=collections
        //https://observablehq.com/@mbostock?type=collections - top 100 obserable
        // top 100 hn users
        // top 100 subreddits
        // top 100 youtube channels
        // top 100 twitter accounts
        // top 100 instagram accounts
        // top 100 tiktok accounts
        // top 100 twitch channels
        // top 100 websites
        // top 100 apps

        //const runtime = new Runtime(stdlib);
        //const main = runtime.module(define, Inspector.into(document.body));
        //fantasai
    </script>
</body>
